{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e24c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some basic settings and directory specification\n",
    "#Ensure these match companion Matlab script (thompsonreplication_mainscript.m)\n",
    "maindatadir='/Volumes/ExternalDriveD/Thompson_savedarrays/';\n",
    "y1=1961;y2=2023;\n",
    "numyrs=y2-y1+1;\n",
    "\n",
    "numregs=237;\n",
    "\n",
    "modelnames=['canesm5','miroc6','mpige'];\n",
    "canesm5_enssz=50;miroc6_enssz=10;mpige_enssz=50;\n",
    "\n",
    "# 1961-2023 global mean surface temp (from NASA GISS: https://climate.nasa.gov/vital-signs/global-temperature/)\n",
    "GMST = [0.06,0.03,0.05,-0.20,-0.11,-0.06,-0.02,-0.08,0.05,0.03,-0.08,0.01,0.16,-0.07,-0.01,\n",
    "        -0.10,0.18,0.07,0.16,0.26,0.32,0.14,0.31,0.16,0.12,0.18,0.32,0.39,0.27,0.45,\n",
    "        0.41, 0.22, 0.23, 0.31, 0.45, 0.33, 0.46, 0.61, 0.38, 0.39, 0.54, 0.63, \n",
    "        0.62, 0.53, 0.68, 0.64, 0.66, 0.54, 0.66, 0.72, 0.61, 0.65, 0.68, 0.74, 0.90, \n",
    "        1.01, 0.92, 0.85, 0.98, 1.01, 0.85, 0.89, 1.17];\n",
    "GMST_yr = np.arange(y1, y2+1, 1);\n",
    "\n",
    "GMST_since1981=GMST[20:];\n",
    "\n",
    "\n",
    "domasking=0; #original default is 1 -- only don't do if wanting to see all regions' data, or if MERRA2 processing hasn't yet been done\n",
    "maskingvs='jra55'; #'merra2' or 'jra55'\n",
    "\n",
    "#Set loop options\n",
    "domainprep=1; #needed upon start-up; runtime 4 min\n",
    "maket23fig2=0;\n",
    "maket23fig3=0;\n",
    "rerunmodelcomp=0; #about 40 min total; needed only if changing GEV set-up\n",
    "convertvalsformapping=0; #NOW CREATED IN MATLAB\n",
    "maket23fig4=0; #Figure 5; NOW CREATED IN MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72afec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import sys\n",
    "sys.path.insert(0, 'Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages');\n",
    "#sys.path.insert(0, 'Users/craymond/LocallyInstalledSoftware');\n",
    "import iris \n",
    "import iris.coord_categorisation as icc\n",
    "from iris.coord_categorisation import add_season_membership\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.plot as iplt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "import glob\n",
    "import matplotlib.cm as mpl_cm\n",
    "from iris.util import equalise_attributes\n",
    "import scipy.stats as sps\n",
    "from scipy.stats import genextreme as gev\n",
    "import random\n",
    "import scipy.io\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "from matplotlib import ticker, cm\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d888b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various functions\n",
    "def time_slice(cube, year1, year2):\n",
    "    year_cons = iris.Constraint(time=lambda cell: year1 <= cell.point.year <= year2)\n",
    "    return cube.extract(year_cons)\n",
    "\n",
    "def cube_to_array(cube):\n",
    "    return cube.data.reshape(np.shape(cube.data)[0]*np.shape(cube.data)[1])\n",
    "\n",
    "def return_levels_plot(distribution_pdf, x_values):\n",
    "    '''\n",
    "    Calculates probability of return levels \n",
    "    '''\n",
    "    chance = []\n",
    "    return_level = []\n",
    "    for i, _ in enumerate(distribution_pdf):\n",
    "        width = x_values[1] - x_values[0]\n",
    "        P = []\n",
    "        for a, b in zip(distribution_pdf[i:-1], distribution_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * width) \n",
    "        chance.append(sum(P)*100)\n",
    "        return_level.append(x_values[i])\n",
    "    return return_level, chance\n",
    "\n",
    "def plot_points(axs_sel, data_array):\n",
    "    obs_sort = np.sort(data_array)\n",
    "    chance = []\n",
    "    for i in range(len(obs_sort)):\n",
    "        chance.append(((i+1) / len(obs_sort)) * 100)\n",
    "    ret_per = []\n",
    "    for each in chance:\n",
    "        ret_per.append(100.*1/each)\n",
    "    ret_per.reverse()\n",
    "    axs_sel.plot(ret_per, obs_sort, '+b', alpha=.5, label='Observed TXx')\n",
    "\n",
    "def plot_gev(axs_sel, data_array, min_val, max_val):\n",
    "    shape, loc, scale = gev.fit(data_array)\n",
    "    #print('shape: ',str(shape))\n",
    "    #print('loc: ',str(loc))\n",
    "    #print('scale: ',str(scale))\n",
    "    x_val = np.linspace(min_val, max_val, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "    chance2 = []\n",
    "    for each in chance[:-1]:\n",
    "        chance2.append(100.*1/each)\n",
    "    axs_sel.plot(chance2[10:], ret_lev[10:-1], color='dodgerblue', label='GEV fit')\n",
    "    \n",
    "def bootstrap_uncertainties(axs_sel, data_array):\n",
    "    # measure of uncertainty in distribution\n",
    "    # 100 bootstraps, plot 5th-95th% range\n",
    "    chance_list = []\n",
    "    for i in np.arange(100):\n",
    "        bootstrap_data = random.choices(data_array, k=len(data_array)) # allows double dipping\n",
    "        shape, loc, scale = gev.fit(bootstrap_data)\n",
    "        x_val = np.linspace(np.min(data_array)-.5, np.max(data_array)+2, 1000)\n",
    "        dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "        ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "        chance_list.append(chance)\n",
    "    chance_5 = []\n",
    "    chance_95 = []\n",
    "    for i in np.arange(1000):\n",
    "        new_val = []\n",
    "        for each in chance_list:\n",
    "            new_val.append(each[i])\n",
    "        chance_5.append(np.sort(new_val)[5])\n",
    "        chance_95.append(np.sort(new_val)[95])\n",
    "    chanceyear_5 = []\n",
    "    chanceyear_95 = []\n",
    "    for i, each in enumerate(chance_5[:-1]):\n",
    "        chanceyear_5.append(100.*1/each)\n",
    "        chanceyear_95.append(100.*1/chance_95[i])\n",
    "    axs_sel.plot(chanceyear_5[10:], ret_lev[10:-1], '--', color='dodgerblue')\n",
    "    axs_sel.plot(chanceyear_95[10:], ret_lev[10:-1], '--', color='dodgerblue', label='Uncertainty (5th-95th%)')\n",
    "\n",
    "def one_in_tenthousand(data_array):\n",
    "    shape, loc, scale = gev.fit(data_array)\n",
    "    x_val = np.linspace(np.min(data_array)-.5, np.max(data_array)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "    return ret_lev[np.abs(np.asarray(chance)-0.01).argmin()]\n",
    "\n",
    "def how_much_higher(data_array):\n",
    "    mod = one_in_tenthousand(data_array)\n",
    "    obs = np.max(data_array)\n",
    "    return mod-obs\n",
    "\n",
    "def plot_data_GMST(axs_sel, ann_max, GMST):\n",
    "    axs_sel.plot(GMST, ann_max, 'b+')\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    bestfit = []\n",
    "    for each in np.sort(GMST): bestfit.append(a*each+b)\n",
    "    axs_sel.plot([np.min(GMST), np.max(GMST)], [np.min(bestfit), np.max(bestfit)], color='dodgerblue')\n",
    "    #axs_sel.set_ylabel('TXx')\n",
    "    #axs_sel.set_xlabel('GMST')\n",
    "\n",
    "def adjust_obs(ann_max, GMST):\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b)) #1*a+b means adjusted for world with 1deg warming  \n",
    "    return offset\n",
    "\n",
    "def plot_EVT(axs_sel, data_array):\n",
    "    axs_sel.set_xscale('log')    \n",
    "    plot_points(axs_sel, data_array)\n",
    "    plot_gev(axs_sel, data_array, np.min(data_array)-.5, np.max(data_array)+2)\n",
    "\n",
    "#Loads main dataset\n",
    "def load_annmax(reg,var): #var can be 'tw' or 't'\n",
    "    return np.loadtxt(maindatadir+'era5output_'+var+'_regions.txt',delimiter=',')[reg,:]; \n",
    "\n",
    "def remove_max(ann_max, GMST):\n",
    "    offset = adjust_obs(ann_max, GMST)\n",
    "    ' Remove the max value from region, and corresponding GMST value '\n",
    "    idx_max = np.where(offset == np.max(offset))[0][0]\n",
    "    ann_max_new = np.delete(ann_max, idx_max)\n",
    "    GMST_new = np.delete(GMST, idx_max)\n",
    "    return ann_max_new, GMST_new\n",
    "\n",
    "def one_in_hundred(data_array):\n",
    "    shape, loc, scale = gev.fit(data_array)\n",
    "    x_val = np.linspace(np.min(data_array)-.5, np.max(data_array)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "    return ret_lev[np.abs(np.asarray(chance)-1).argmin()]\n",
    "\n",
    "def plot_data_GMST(axs_sel, ann_max, GMST):\n",
    "    axs_sel.plot(GMST, ann_max, '+', label='Observed TXx')\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    bestfit = []\n",
    "    for each in np.sort(GMST): bestfit.append(a*each+b)\n",
    "    axs_sel.plot([np.min(GMST), np.max(GMST)], [np.min(bestfit), np.max(bestfit)], label='Fit')\n",
    "    \n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "def regrid(data, out_x, out_y):\n",
    "    m = max(data.shape[0], data.shape[1])\n",
    "    y = np.linspace(0, 1.0/m, data.shape[0])\n",
    "    x = np.linspace(0, 1.0/m, data.shape[1])\n",
    "    interpolating_function = RegularGridInterpolator((y, x), data)\n",
    "\n",
    "    yv, xv = np.meshgrid(np.linspace(0, 1.0/m, out_y), np.linspace(0, 1.0/m, out_x))\n",
    "\n",
    "    return interpolating_function((xv, yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e96cdd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More functions\n",
    "def offset_higher(reg,var):\n",
    "    ''' loads data, \n",
    "    applies offset to present day, \n",
    "    calcs difference between observed max and 1-in-10000 event'''\n",
    "    #var can be 't', 'tw', or 'twdatasetmean' (the latter being an ERA5/JRA55 mean)\n",
    "    if var=='t' or var=='tw':\n",
    "        ann_max = load_annmax(reg,var)\n",
    "    elif var=='twdatasetmean':\n",
    "        tmp_era5=np.loadtxt(maindatadir+'era5output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        tmp_jra55=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        ann_max=(tmp_era5+tmp_jra55)/2;\n",
    "    elif var=='tw_jra55':\n",
    "        ann_max=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        \n",
    "    # Adjust ann max to distance from best fit\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  # np.mean to make 'present day'\n",
    "    val = how_much_higher(offset)\n",
    "    return val\n",
    "\n",
    "def offset_higher_removeevent(reg,var):\n",
    "    ''' loads data, \n",
    "    applies offset to present day, \n",
    "    calcs difference between observed max and 1-in-10000 event'''\n",
    "    #var can be 't', 'tw', or 'twdatasetmean' (the latter being an ERA5/JRA55 mean)\n",
    "    if var=='t' or var=='tw':\n",
    "        ann_max = load_annmax(reg,var)\n",
    "    elif var=='twdatasetmean':\n",
    "        tmp_era5=np.loadtxt(maindatadir+'era5output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        tmp_jra55=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        ann_max=(tmp_era5+tmp_jra55)/2;\n",
    "    elif var=='tw_jra55':\n",
    "        ann_max=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        \n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  #adjust for world with 1 deg of warming\n",
    "    ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "    # Adjust ann max to distance from best fit\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "    for i, each in enumerate(ann_max_new):\n",
    "        actual = each\n",
    "        predicted = GMST_new[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  # np.mean to make 'present day'\n",
    "    tenthos = one_in_tenthousand(offset)\n",
    "    offset_full = []\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset_full.append(actual-predicted+(1*a+b))\n",
    "    max_val = np.max(offset_full)\n",
    "    return tenthos - max_val\n",
    "\n",
    "def obs_max_ret_per_removeevent(reg,var):\n",
    "    ' Returns the highest event in terms of return period, yrs '\n",
    "    #var can be 't', 'tw', or 'twdatasetmean' (the latter being an ERA5/JRA55 mean)\n",
    "    if var=='t' or var=='tw':\n",
    "        ann_max = load_annmax(reg,var)\n",
    "    elif var=='twdatasetmean':\n",
    "        tmp_era5=np.loadtxt(maindatadir+'era5output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        tmp_jra55=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        ann_max=(tmp_era5+tmp_jra55)/2;\n",
    "    elif var=='tw_jra55':\n",
    "        ann_max=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        \n",
    "    ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "    offset_new = []\n",
    "    a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "    for i, each in enumerate(ann_max_new):\n",
    "        actual = each\n",
    "        predicted = GMST_new[i]*a +b\n",
    "        offset_new.append(actual-predicted+(1*a+b)) #adjust for world with 1 deg of warming\n",
    "        \n",
    "    shape, loc, scale = gev.fit(offset_new) # EVT distribution without observed max\n",
    "    x_val = np.linspace(np.min(offset_new)-.5, np.max(offset_new)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    \n",
    "    offset_full = []\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset_full.append(actual-predicted+(1*a+b))\n",
    "        \n",
    "    max_val = np.max(offset_full) #observed max\n",
    "    chance = []\n",
    "    for i, _ in enumerate(dist_pdf):\n",
    "        P = []\n",
    "        for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "        chance.append(sum(P)*100)\n",
    "    x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "    if x == 0:\n",
    "        result_new = 99999\n",
    "    else:\n",
    "        result_new = 100.*1/x\n",
    "    return result_new\n",
    "\n",
    "def obs_max_ret_per(reg,var):\n",
    "    ' Returns the highest event in terms of return period, yrs '\n",
    "    #var can be 't', 'tw', or 'twdatasetmean' (the latter being an ERA5/JRA55 mean)\n",
    "    if var=='t' or var=='tw':\n",
    "        ann_max = load_annmax(reg,var)\n",
    "    elif var=='twdatasetmean':\n",
    "        tmp_era5=np.loadtxt(maindatadir+'era5output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        tmp_jra55=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        ann_max=(tmp_era5+tmp_jra55)/2;\n",
    "    elif var=='tw_jra55':\n",
    "        ann_max=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=',')[reg,:];\n",
    "        \n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  #adjust for world with 1 deg of warming\n",
    "        \n",
    "    max_val = np.max(offset)\n",
    "    shape, loc, scale = gev.fit(offset) # EVT distribution\n",
    "    x_val = np.linspace(np.min(offset)-.5, np.max(offset)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    chance = []\n",
    "    for i, _ in enumerate(dist_pdf):\n",
    "        P = []\n",
    "        for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "        chance.append(sum(P)*100)\n",
    "    x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "    if x == 0:\n",
    "        result = 99999\n",
    "    else:\n",
    "        result = 100.*1/x\n",
    "    return result\n",
    "\n",
    "def offset_maxval(reg,var):\n",
    "    ann_max = load_annmax(reg,var)\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  # np.mean to make 'present day'\n",
    "    max_val = np.max(offset) # Maximum observed\n",
    "    return max_val\n",
    "\n",
    "def abs_max(reg,var):\n",
    "    ann_max = load_annmax(reg,var)\n",
    "    return np.max(ann_max)\n",
    "\n",
    "def offset_100(reg,var):\n",
    "    ann_max = load_annmax(reg,var)\n",
    "    ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "    for i, each in enumerate(ann_max_new):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))  # np.mean to make 'present day'\n",
    "    shape, loc, scale = gev.fit(offset) # EVT distribution\n",
    "    x_val = np.linspace(np.min(offset)-.5, np.max(offset)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    #dist_cdf = gev.cdf(x_val, shape, loc, scale)\n",
    "    ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "    chance2 = []\n",
    "    for each in chance[:-1]:\n",
    "        chance2.append(100.*1/each)\n",
    "    return ret_lev[(np.abs(np.asarray(chance2)-100)).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260580fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Troubleshooting the above\n",
    "reg=116;var='tw';\n",
    "ann_max = np.loadtxt(maindatadir+'era5output_'+var+'_regions.txt',delimiter=',')[reg,:]; \n",
    "\n",
    "#With observed max\n",
    "offset = []\n",
    "a, b = np.polyfit(GMST, ann_max, 1)\n",
    "for i, each in enumerate(ann_max):\n",
    "    actual = each\n",
    "    predicted = GMST[i]*a +b\n",
    "    offset.append(actual-predicted+(1*a+b))  #adjust for world with 1 deg of warming\n",
    "\n",
    "#GEV fit with observed max\n",
    "max_val = np.max(offset)\n",
    "shape, loc, scale = gev.fit(offset) # EVT distribution\n",
    "x_val = np.linspace(np.min(offset)-.5, np.max(offset)+2, 1000)\n",
    "dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "chance = []\n",
    "for i, _ in enumerate(dist_pdf):\n",
    "    P = []\n",
    "    for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "        P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "    chance.append(sum(P)*100)\n",
    "x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "if x == 0:\n",
    "    result = 99999\n",
    "else:\n",
    "    result = 100.*1/x\n",
    "\n",
    "\n",
    "#Without observed max\n",
    "ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "offset_new = []\n",
    "a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "for i, each in enumerate(ann_max_new):\n",
    "    actual = each\n",
    "    predicted = GMST_new[i]*a +b\n",
    "    offset_new.append(actual-predicted+(1*a+b)) #adjust for world with 1 deg of warming\n",
    "\n",
    "#GEV fit without observed max\n",
    "shape, loc, scale = gev.fit(offset_new) # EVT distribution without observed max\n",
    "x_val = np.linspace(np.min(offset_new)-.5, np.max(offset_new)+2, 1000)\n",
    "dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "\n",
    "offset_full = []\n",
    "for i, each in enumerate(ann_max):\n",
    "    actual = each\n",
    "    predicted = GMST[i]*a +b\n",
    "    offset_full.append(actual-predicted+(1*a+b))\n",
    "\n",
    "max_val = np.max(offset_full) #observed max\n",
    "chance = []\n",
    "for i, _ in enumerate(dist_pdf):\n",
    "    P = []\n",
    "    for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "        P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "    chance.append(sum(P)*100)\n",
    "x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "if x == 0:\n",
    "    result_new = 99999\n",
    "else:\n",
    "    result_new = 100.*1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a249c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f9ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare ERA5 and JRA55 annual-max data to check for inconsistencies\n",
    "#Regions that are inconsistent will be masked in subsequent figures\n",
    "#Runtime 3 sec\n",
    "era5regannmax_tw=np.loadtxt(maindatadir+'era5output_tw_regions.txt',delimiter=','); \n",
    "era5regannmax_t=np.loadtxt(maindatadir+'era5output_t_regions.txt',delimiter=','); \n",
    "jra55regannmax_tw=np.loadtxt(maindatadir+'jra55output_tw_regions.txt',delimiter=','); \n",
    "jra55regannmax_t=np.loadtxt(maindatadir+'jra55output_t_regions.txt',delimiter=','); \n",
    "if domasking==1:\n",
    "    if maskingvs=='merra2':\n",
    "        merra2regannmax_tw=np.loadtxt(maindatadir+'merra2output_tw_regions.txt',delimiter=','); \n",
    "        merra2regannmax_t=np.loadtxt(maindatadir+'merra2output_t_regions.txt',delimiter=','); \n",
    "    \n",
    "\n",
    "def adjust_obs_1981(ann_max): \n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST_since1981, ann_max, 1)\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST_since1981[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b)) #1*a+b means adjusted for world with 1deg warming  \n",
    "    return offset\n",
    "\n",
    "def year_max_adjust(ann_max):\n",
    "    x = adjust_obs(ann_max,GMST) \n",
    "    year = np.arange(y1, y2+1)\n",
    "    yr = year[np.where(x==np.amax(x))[0]][0]\n",
    "    return yr\n",
    "\n",
    "def year_max_adjust_1981(ann_max):\n",
    "    x = adjust_obs_1981(ann_max) \n",
    "    year = np.arange(y1+20, y2+1) #1981-end\n",
    "    yr = year[np.where(x==np.amax(x))[0]][0]\n",
    "    return yr\n",
    "\n",
    "def year_max(ann_max):\n",
    "    x = ann_max\n",
    "    year = np.arange(y1, y2)\n",
    "    yr = year[np.where(x==np.amax(x))[0]][0]\n",
    "    return yr\n",
    "\n",
    "def year_max_multiple_adjust(ann_max, how_many):\n",
    "    x = adjust_obs(ann_max,GMST) #detrend timeseries\n",
    "    year = np.arange(y1, y2+1)\n",
    "    yr = []\n",
    "    for each in np.sort(x)[-how_many:]:\n",
    "        yr.append(year[np.where(x==each)[0]][0])\n",
    "    return yr\n",
    "\n",
    "def year_max_multiple_adjust_1981(ann_max, how_many):\n",
    "    x = adjust_obs_1981(ann_max) #detrend timeseries\n",
    "    year = np.arange(y1+20, y2+1) #1981-end\n",
    "    yr = []\n",
    "    for each in np.sort(x)[-how_many:]:\n",
    "        yr.append(year[np.where(x==each)[0]][0])\n",
    "    return yr\n",
    "\n",
    "\n",
    "#zeros -- regions to be masked due to inconsistency between datasets\n",
    "if domasking==1:\n",
    "    #Tw\n",
    "    mylist = []\n",
    "    for reg in range(numregs):\n",
    "        if maskingvs=='merra2':\n",
    "            ann_max=merra2regannmax_tw[reg][20:];how_many=5;\n",
    "            merra2_yr=year_max_multiple_adjust_1981(ann_max, how_many); #top few years in this region selon MERRA2\n",
    "\n",
    "            ann_max=era5regannmax_tw[reg][20:];\n",
    "            era_yr=year_max_adjust_1981(ann_max); #top year for ERA5\n",
    "\n",
    "            if era_yr in merra2_yr:\n",
    "                mylist.append(1)\n",
    "            else:\n",
    "                mylist.append(0)\n",
    "                \n",
    "        elif maskingvs=='jra55':\n",
    "            ann_max=jra55regannmax_tw[reg];how_many=5;\n",
    "            jra55_yr=year_max_multiple_adjust(ann_max, how_many); #top few years in this region selon JRA55\n",
    "\n",
    "            ann_max=era5regannmax_tw[reg];\n",
    "            era_yr=year_max_adjust(ann_max); #top year for ERA5\n",
    "\n",
    "            if era_yr in jra55_yr:\n",
    "                mylist.append(1)\n",
    "            else:\n",
    "                mylist.append(0)\n",
    "\n",
    "    mask_regs_tw = mylist\n",
    "    \n",
    "    #T\n",
    "    mylist = []\n",
    "    for reg in range(numregs):\n",
    "        if maskingvs=='merra2':\n",
    "            ann_max=merra2regannmax_t[reg][20:];how_many=5;\n",
    "            merra2_yr=year_max_multiple_adjust_1981(ann_max, how_many); #top few years in this region selon MERRA2\n",
    "\n",
    "            ann_max=era5regannmax_t[reg][20:];\n",
    "            era_yr=year_max_adjust_1981(ann_max); #top year for ERA5\n",
    "\n",
    "            if era_yr in merra2_yr:\n",
    "                mylist.append(1)\n",
    "            else:\n",
    "                mylist.append(0)\n",
    "                \n",
    "        elif maskingvs=='jra55':\n",
    "            ann_max=jra55regannmax_t[reg];how_many=5;\n",
    "            jra55_yr=year_max_multiple_adjust(ann_max, how_many); #top few years in this region selon JRA55\n",
    "\n",
    "            ann_max=era5regannmax_t[reg];\n",
    "            era_yr=year_max_adjust(ann_max); #top year for ERA5\n",
    "\n",
    "            if era_yr in jra55_yr:\n",
    "                mylist.append(1)\n",
    "            else:\n",
    "                mylist.append(0)\n",
    "\n",
    "    mask_regs_t = mylist\n",
    "else:\n",
    "    mask_regs_tw=np.ones((numregs,));\n",
    "    mask_regs_t=np.ones((numregs,));\n",
    "\n",
    "np.savetxt(maindatadir+\"mask_regs_tw_\"+maskingvs+\".csv\", np.array(mask_regs_tw), delimiter=\",\",fmt='%10.0f')\n",
    "np.savetxt(maindatadir+\"mask_regs_t_\"+maskingvs+\".csv\", np.array(mask_regs_t), delimiter=\",\",fmt='%10.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23f37ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute difference between record and 1-in-100 event using GMST-adjusted data\n",
    "#Uses ERA5/JRA55 mean\n",
    "#Runtime 15 sec\n",
    "era5regannmax_adj_tw=np.loadtxt(maindatadir+'era5output_tw_adj_regions.txt',delimiter=',');\n",
    "#jra55regannmax_adj_tw=np.loadtxt(maindatadir+'jra55output_tw_adj_regions.txt',delimiter=',');\n",
    "hundred_rec_diff=np.zeros((numregs,));\n",
    "for reg in range(numregs):\n",
    "    era5arr=era5regannmax_adj_tw[reg,:];\n",
    "    #jra55arr=jra55regannmax_adj_tw[reg,:];\n",
    "    #myarr=(era5arr+jra55arr)/2;\n",
    "    myarr=era5arr;\n",
    "    myrec=np.max(myarr);\n",
    "    \n",
    "    oneinhundredval=one_in_hundred(myarr);\n",
    "    hundred_rec_diff[reg]=oneinhundredval-myrec; #i.e. 1-in-100 value is this many degrees higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0218d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3e1e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ERA5: set up regional data, implement regional mask if desired, and do GEV fit\n",
    "#Note that this loop ingests raw data and GMST-adjusts it -- don't feed it already GMST-adjusted data!!\n",
    "#Cell runtime: 4 min for all loops\n",
    "if domainprep==1:\n",
    "    regs_in_ant = np.arange(170, 191);numregs_ant=21; #ordinates of the 21 Antarctica regions to remove\n",
    "    numregs_noant=numregs-numregs_ant;\n",
    "\n",
    "    #Preliminarily load region data\n",
    "    region_fp = maindatadir+'region_fx-WRAF05-v4-1_WRAF_All-Hist_est1_v4-1_4-1-0_000000-000000.nc'\n",
    "    region_ds = xr.open_mfdataset(region_fp, parallel=True)\n",
    "    lats = region_ds.lat\n",
    "    lons = region_ds.lon\n",
    "    \n",
    "    orignumlats=np.shape(region_ds.region)[0];orignumlons=orignumlats*2;\n",
    "    \n",
    "    #Reduce lat and lon resolution each by a factor of 2 (still very high res) to avoid killing the kernel\n",
    "    if ~('coarserregs' in globals()):\n",
    "        coarserregs=np.round(regrid(np.array(region_ds.region.values),int(orignumlats/2),int(orignumlons/2)));\n",
    "    \n",
    "\n",
    "    for loop in range(3,4): #default is 0,3\n",
    "        if loop==0:\n",
    "            var='tw';fnamepart='tw_era5';regannmax=era5regannmax_tw;mask_regs=mask_regs_tw;\n",
    "        elif loop==1:\n",
    "            var='t';fnamepart='t_era5';regannmax=era5regannmax_t;mask_regs=mask_regs_t;\n",
    "        elif loop==2: #Mean of datasets\n",
    "            var='twdatasetmean';fnamepart='tw_datasetmean';regannmax=(era5regannmax_tw+jra55regannmax_tw)/2;mask_regs=mask_regs_tw;\n",
    "        elif loop==3: #JRA55 Tw\n",
    "            var='tw_jra55';fnamepart='tw_jra55';regannmax=jra55regannmax_tw;mask_regs=mask_regs_tw;\n",
    "            \n",
    "        regords_noant = [] #region ordinates\n",
    "        vals_actual_noant = [] #actual values\n",
    "        vals_retper_noant = [] #return periods\n",
    "        vals_retper_noant_withtopevents = [] #return periods with top events included\n",
    "        vals_abs_noant = [] #difference between observed max and statistical max\n",
    "        for each in np.arange(numregs):\n",
    "            regords_noant.append(each)\n",
    "            vals_actual_noant.append(np.max(regannmax[each,:]))\n",
    "            vals_retper_noant.append(obs_max_ret_per_removeevent(each,var)) #Return periods\n",
    "            vals_retper_noant_withtopevents.append(obs_max_ret_per(each,var)) #Return periods with top events included\n",
    "            vals_abs_noant.append(offset_higher_removeevent(each,var)) #Highest values (C)\n",
    "\n",
    "        #vals_retper_noant = [np.nan if x == 99999 else x for x in vals_retper_noant]\n",
    "\n",
    "        # Convert vals to regional data for mapping\n",
    "        region_ord=coarserregs; #just to initialize\n",
    "        region_actual=coarserregs;\n",
    "        region_abs = coarserregs;\n",
    "        region_retper = coarserregs;\n",
    "        region_retper_withtopevents = coarserregs;\n",
    "        for r in range(numregs):\n",
    "            region_ord = np.where(coarserregs != r, region_ord, regords_noant[r]); #condition, val if true, val if false\n",
    "            region_actual = np.where(coarserregs != r, region_actual, vals_actual_noant[r])\n",
    "            region_retper = np.where(coarserregs != r, region_retper, vals_retper_noant[r])\n",
    "            region_retper_withtopevents = np.where(coarserregs != r, region_retper_withtopevents, vals_retper_noant_withtopevents[r])\n",
    "            region_abs = np.where(coarserregs != r, region_abs, vals_abs_noant[r])\n",
    "            #region_abs = region_abs.where(coarserregs != r, vals_abs_noant[r])\n",
    "\n",
    "\n",
    "        # Zeros in mask arrays-- regions that will be shaded dark grey in the final plot\n",
    "        # Antarctica not included here as it is assumed to be excluded\n",
    "\n",
    "        #For comparison -- mask from Thompson et al. 2023\n",
    "        reg_mask_t = [1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
    "                    0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, \n",
    "                    0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, \n",
    "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, \n",
    "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, \n",
    "                    1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, \n",
    "                    0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1];\n",
    "\n",
    "        #reg_mask=np.concatenate((np.transpose(mask_regs[:170]),np.transpose(mask_regs[191:238])));\n",
    "        reg_mask=mask_regs;\n",
    "            #good regions are 1, bad regions are 0\n",
    "        reg_mask = [np.nan if x == 1 else x for x in reg_mask] \n",
    "            #good regions are nan (i.e. will not be covered up), bad regions are 0\n",
    "        #region_mask = np.array(region_ds.region); #initialize\n",
    "        region_mask = coarserregs;\n",
    "\n",
    "        #NEW\n",
    "        for region in range(numregs):\n",
    "            region_mask[region_mask==region]=reg_mask[region];\n",
    "\n",
    "\n",
    "\n",
    "        #For reference   \n",
    "        regcenterpoints=np.loadtxt(maindatadir+'region_centerpoints.csv',delimiter=',');\n",
    "        regcenterlats_tmp=regcenterpoints[:,0].tolist();\n",
    "        regcenterlons_tmp=regcenterpoints[:,1].tolist();\n",
    "        regcenterlats_noant=np.concatenate((np.transpose(regcenterlats_tmp[:170]),np.transpose(regcenterlats_tmp[191:238])));\n",
    "        regcenterlons_noant=np.concatenate((np.transpose(regcenterlons_tmp[:170]),np.transpose(regcenterlons_tmp[191:238])));\n",
    "\n",
    "\n",
    "        np.savetxt(maindatadir+\"currentrecordreturnperiods_\"+fnamepart+\".csv\", np.array(vals_retper_noant), \n",
    "                   delimiter=\",\",fmt='%10.2f')\n",
    "        np.savetxt(maindatadir+\"currentrecordreturnperiods_withtopevents_\"+fnamepart+\".csv\", \n",
    "                   np.array(vals_retper_noant_withtopevents), delimiter=\",\",fmt='%10.2f')\n",
    "\n",
    "        if loop==0:\n",
    "            region_ord_tw=region_ord;region_actual_tw=region_actual;region_retper_tw=region_retper;\n",
    "            region_abs_tw=region_abs;region_mask_tw=region_mask;\n",
    "            vals_actual_noant_tw=vals_actual_noant;\n",
    "            vals_retper_noant_tw=vals_retper_noant;\n",
    "            vals_retper_noant_withtopevents_tw=vals_retper_noant_withtopevents;\n",
    "            vals_abs_noant_tw=vals_abs_noant;\n",
    "        elif loop==1:\n",
    "            region_ord_t=region_ord;region_actual_t=region_actual;region_retper_t=region_retper;\n",
    "            region_abs_t=region_abs;region_mask_t=region_mask;\n",
    "            vals_actual_noant_t=vals_actual_noant;vals_retper_noant_t=vals_retper_noant;\n",
    "            vals_abs_noant_t=vals_abs_noant;\n",
    "        elif loop==2:\n",
    "            region_ord_tw_datasetmean=region_ord;region_actual_tw_datasetmean=region_actual;\n",
    "            region_retper_tw_datasetmean=region_retper;\n",
    "            region_abs_tw_datasetmean=region_abs;region_mask_tw_datasetmean=region_mask;\n",
    "            vals_actual_noant_tw_datasetmean=vals_actual_noant;vals_retper_noant_tw_datasetmean=vals_retper_noant;\n",
    "            vals_abs_noant_tw_datasetmean=vals_abs_noant;\n",
    "            \n",
    "        #del region_ord;del region_actual;del region_retper;del region_abs;del region_mask;\n",
    "\n",
    "        #plt.imshow(region_mask);plt.colorbar()\n",
    "\n",
    "del region_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce99d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7d1d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map of actual regional Tw annual maxes (from ERA5) -- 1 min\n",
    "dothis=0;\n",
    "if dothis==1:\n",
    "    fig, axs = plt.subplots(2,1,figsize=(10., 7.), dpi=80, num=None, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    c = axs[0].contourf(lons,lats,region_actual_tw,11,transform=ccrs.PlateCarree(),\n",
    "                        cmap=mpl_cm.get_cmap('bwr'), vmin=0, vmax=30) # or try 'bwr''coolwarm'\n",
    "    cbar = plt.colorbar(c, shrink=0.7, ax=axs[0])\n",
    "    b = axs[0].contourf(lons,lats,region_mask_tw,11,transform=ccrs.PlateCarree(), colors='darkgrey', vmin=-1, vmax=1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "#Map of region ordinates -- 1 min\n",
    "#fig, axs = plt.subplots(2,1,figsize=(10., 7.), dpi=80, num=None, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "#c = axs[0].contourf(lons,lats,region_ord,11,transform=ccrs.PlateCarree(),\n",
    "#                    cmap=mpl_cm.get_cmap('jet'), vmin=0, vmax=numregs) # or try 'bwr''coolwarm'\n",
    "#cbar = plt.colorbar(c, shrink=0.7, ax=axs[0])\n",
    "#b = axs[0].contourf(lons,lats,region_mask,11,transform=ccrs.PlateCarree(), colors='darkgrey', vmin=-1, vmax=1)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477ef96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de47b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actually make analogue to T23 Figure 2\n",
    "#Cell runtime: 1 min per variable\n",
    "\n",
    "if maket23fig2==1:\n",
    "    var='tw'; #can be 'tw' or 't'\n",
    "\n",
    "    if var=='tw':\n",
    "        region_abs=region_abs_tw;region_retper=region_retper_tw;region_mask=region_mask_tw;var_title='Tw';\n",
    "    else:\n",
    "        region_abs=region_abs_t;region_retper=region_retper_t;region_mask=region_mask_t;var_title='T';\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10., 7.), dpi=80, num=None, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    # Statistical maximum difference plot\n",
    "    c = axs[0].contourf(lons,lats,region_abs,11,transform=ccrs.PlateCarree(),\n",
    "                        cmap=mpl_cm.get_cmap('bwr'), vmin=-3.5, vmax=3.5) # or try 'bwr''coolwarm'\n",
    "    cbar = plt.colorbar(c, shrink=0.7, ax=axs[0])\n",
    "    b = axs[0].contourf(lons,lats,region_mask,11,transform=ccrs.PlateCarree(), colors='darkgrey', vmin=-1, vmax=1)\n",
    "    cbar.set_label(u\"\\u2103\", fontsize=12)\n",
    "    cbar.outline.set_linewidth(0.5)\n",
    "    #cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), ha='right')\n",
    "    cbar.ax.tick_params(labelsize=12,pad=40)\n",
    "    axs[0].set_title('Statistical maximum ('+var_title+') minus current record')\n",
    "    axs[0].text(-190, 95, 'a')\n",
    "    # Current return period plot\n",
    "    e = axs[1].contourf(lons,lats,region_abs,11,transform=ccrs.PlateCarree(),\n",
    "                        colors='r',\n",
    "                        vmin=-10, vmax=30)\n",
    "    levels=np.logspace(np.log10(1),np.log10(10000),5)\n",
    "    d = axs[1].contourf(lons,lats,region_retper,11,transform=ccrs.PlateCarree(),\n",
    "                        cmap=mpl_cm.get_cmap('Blues'),\n",
    "                        levels=levels, locator=ticker.LogLocator(base=10))\n",
    "    b = axs[1].contourf(lons,lats,region_mask,11,transform=ccrs.PlateCarree(), colors='darkgrey', vmin=-1, vmax=1)\n",
    "\n",
    "    axs[1].set_title('Current record return period ('+var_title+')')\n",
    "    axs[1].text(-190, 95, 'b')\n",
    "    cbar = plt.colorbar(d, shrink=0.7, ax = axs[1], ticks=ticker.LogLocator(base=10))\n",
    "    cbar.set_label('Years', fontsize=12)\n",
    "    cbar.outline.set_linewidth(0.5)\n",
    "    cbar.ax.tick_params(labelsize=12,width=0.5)\n",
    "\n",
    "    axs[1].text(-170, -35, 'Exceptional', fontsize = 10, \n",
    "             bbox = dict(facecolor = 'red', alpha = 0.5))\n",
    "    axs[1].text(-170, -50, 'Inconsistent data', fontsize = 10, \n",
    "             bbox = dict(facecolor = 'darkgrey', alpha = 0.5))\n",
    "\n",
    "    for axes in axs:\n",
    "        axes.coastlines()\n",
    "        axes.set_ylim([-60, 90])\n",
    "        #axes.outline_patch.set_linewidth(1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('replication_fig2_'+var+'.png', dpi=300)\n",
    "    #plt.savefig('fig2_final.pdf')\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a38b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make T23 Figure 3\n",
    "#Cell runtime: 10 sec\n",
    "\n",
    "#Freshly redefine reg_mask\n",
    "#reg_mask=np.concatenate((np.transpose(mask_regs[:170]),np.transpose(mask_regs[191:238])));\n",
    "#reg_mask = [np.nan if x == 1 else x for x in reg_mask] \n",
    "\n",
    "if maket23fig3==1:\n",
    "    for loop in range(0,2):\n",
    "        if loop==0:\n",
    "            var='tw';reg_mask=mask_regs_tw;\n",
    "            vals_retper_noant=vals_retper_noant_tw;vals_abs_noant=vals_abs_noant_tw;\n",
    "            blabelpos=1.55;\n",
    "        elif loop==1:\n",
    "            var='t';reg_mask=mask_regs_t;\n",
    "            vals_retper_noant=vals_retper_noant_t;vals_abs_noant=vals_abs_noant_t;\n",
    "            blabelpos=4.55;\n",
    "\n",
    "\n",
    "        reg_mask = [np.nan if x == 1 else x for x in reg_mask] \n",
    "\n",
    "\n",
    "        # Remove the Antarctic regions, then apply the masking\n",
    "        reg_retper = vals_retper_noant.copy()\n",
    "        reg_abs = vals_abs_noant.copy()\n",
    "\n",
    "        for each in regs_in_ant[::-1]:\n",
    "            reg_retper.pop(each)\n",
    "            reg_abs.pop(each)\n",
    "            reg_mask.pop(each)\n",
    "\n",
    "        retper_mask = []\n",
    "        abs_mask = []\n",
    "        for i, each in enumerate(reg_mask):\n",
    "            if np.isnan(each):\n",
    "                retper_mask.append(reg_retper[i])\n",
    "                abs_mask.append(reg_abs[i])\n",
    "            else: pass\n",
    "\n",
    "        ## Scatter of two measures - where nan\n",
    "        def obs_max_year(reg,var):\n",
    "            ' Returns the highest event in terms of return period, yrs '\n",
    "            ann_max = load_annmax(reg,var)\n",
    "            max = np.where(ann_max == np.max(ann_max))[0][0]\n",
    "            return max+y1 # index -> year\n",
    "\n",
    "        vals_wherenan = []\n",
    "        year_wherenan = []\n",
    "        for i, each in enumerate(reg_retper):\n",
    "            if np.isnan(reg_mask[i]):\n",
    "                if np.isnan(each):\n",
    "                    vals_wherenan.append(reg_abs[i])\n",
    "                    year_wherenan.append(obs_max_year(i,var))\n",
    "\n",
    "\n",
    "        ## regions' population data, from excel sheet\n",
    "        pop2020 = [35058, 9362.0, 36778.0, 4244.0, 7085, 155.0, 7784.0, 123699, 3768962, 3838695, 1275069, 1463330.0, \n",
    "               280330.0, 14180861.0, 39153.0, 7285067, 2248624, 6525, 573490.0, 11999838, 2697617, 8547714, 24082918.0,\n",
    "               11842203, 39273866.0, 40107493, 8384732, 24665718, 12264077, 63378369.0, 35493739, 33887421, 1776601, \n",
    "               443288, 4961768.0, 1375779, 6042843, 31150375, 11773314, 619124, 1984691, 10275139, 39445384, 80088461, \n",
    "               4127100, 4561119, 2973924, 30302763, 495720, 6688702, 29372864, 1777633, 32093533, 173174, 3626562, \n",
    "               35863592, 686558, 185412, 1058910, 1833886, 5124811, 9067462, 4789973, 28279744, 86327318, 1185522, \n",
    "               75910653, 13776194, 14810497, 5318217, 20417405, 29934246, 7901607, 32427030, 2057012, 17175842, \n",
    "               25703520, 64430782, 498206, 19633883, 73703476.0, 114829191, 228727, 13651192.0, 22070496.0, 4668836, \n",
    "               6345789, 17137553, 17125552.0, 28038064, 18433425.0, 11323533, 12411156, 35074065.0, 35005949.0, \n",
    "               17973787.0, 25106274, 25749291.0, 2580356, 2124047, 12522729, 39674125, 3300780, 884918, 40451661, \n",
    "               22175302, 23963980, 19123720, 302242.0, 1516770, 4522402, 9248667, 182013.0, 513, 3062310, 1289081.0, \n",
    "               2773401.0, 1054825, 281, 114.0, 104012, 9724, 293647, 132290, 17011, 356977, 2011401, 1432453, 74370541,\n",
    "               5351986, 27571533.0, 53411661, 14602262, 12217481, 1233655, 4359458, 3241555.0, 3239493.0, 5006886.0, \n",
    "               38755552, 197725186, 10665078, 7519179, 1034334, 31269113, 4808374, 11947485, 13950923, 67500374, \n",
    "               250297823.0, 704816, 1048482, 115213313, 75085565, 176968847, 267801195, 142034915, 144861962, 21875, \n",
    "               46092, 601818, 48198, 6191, 1245302, 7596027, 42121, 49716, 316674, 395350, 2590528, 0.0, 0.0, 0.0, 0.0,\n",
    "               0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47199454, 2288772, \n",
    "               22792175, 1392269, 3761272, 7087663, 75580294.0, 9126748, 10695544, 110276787.0, 65017756, 51612076.0, \n",
    "               64729722, 68988873, 34947609, 153658397, 427316337, 173377780, 258059259, 279816308, 44303465, 110458041,\n",
    "               69831788, 114120493, 203805030, 12323013, 17031880, 2039.0, 0.0, 872.0, 8044559.0, 16474411, 73425997, \n",
    "               21716337, 10139072, 84906918, 14565540, 91121993.0, 600857, 2097275, 349775, 45466417.0, 17321153.0, \n",
    "               41271482, 153926924, 7491016];\n",
    "\n",
    "\n",
    "        #Also read in region center points, so regions can be tracked after masking, etc\n",
    "        regcenterpoints=np.loadtxt(maindatadir+'region_centerpoints.csv',delimiter=',');\n",
    "        regcenterlats=regcenterpoints[:,0].tolist();\n",
    "        regcenterlons=regcenterpoints[:,1].tolist();\n",
    "\n",
    "        origords=[*range(0,numregs)];\n",
    "\n",
    "\n",
    "        for each in regs_in_ant[::-1]:\n",
    "            pop2020.pop(each)\n",
    "            regcenterlats.pop(each)\n",
    "            regcenterlons.pop(each)\n",
    "            origords.pop(each)\n",
    "\n",
    "        pop_mask = [];centerlats_mask = [];centerlons_mask = [];origords_mask=[];\n",
    "        for i, each in enumerate(reg_mask):\n",
    "            if np.isnan(each):\n",
    "                pop_mask.append(pop2020[i])\n",
    "                centerlats_mask.append(regcenterlats[i])\n",
    "                centerlons_mask.append(regcenterlons[i])\n",
    "                origords_mask.append(origords[i])\n",
    "            else: pass\n",
    "\n",
    "\n",
    "        #Now, we're ready to do the plotting\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10., 4.), dpi=80)\n",
    "        axs[0].plot(retper_mask, pop_mask, '+', label='Regional records')\n",
    "        axs[0].set_xlabel('Return Period of current record (Years)', fontsize=12)\n",
    "        axs[0].set_ylabel('Population in 2020', fontsize=12)\n",
    "        axs[0].set_xscale('log')\n",
    "        axs[0].set_yscale('log')\n",
    "        axs[0].grid()\n",
    "        #axs[0].plt.arrow(10**6, 10**3, 10**5, 10**\n",
    "        axs[0].text(17, 8E8, 'a')\n",
    "        axs[0].legend(loc='lower right')\n",
    "        for i in range(len(vals_wherenan)): vals_wherenan[i] = -vals_wherenan[i]\n",
    "\n",
    "        axs[1].plot(year_wherenan, vals_wherenan, '+', label='Regional records')\n",
    "        #if var=='t':\n",
    "            #axs[1].plot([2021, 2021], np.sort(vals_wherenan)[-2:], 'r+', label='Western North America heatwave')\n",
    "        axs[1].set_xlim(y1-1,y2+1);\n",
    "        axs[1].set_xlabel('Year', fontsize=12)\n",
    "        axs[1].set_ylabel('How far beyond statistical maximum, '+u\"\\u2103\", fontsize=12)\n",
    "        axs[1].grid()\n",
    "        axs[1].text(y1-2, blabelpos, 'b')\n",
    "        axs[1].legend(loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('fig3_final_'+var+'.png', dpi=300)\n",
    "        #plt.savefig('fig3_final.pdf')\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f2181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8fa5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions supporting model analysis\n",
    "def remove_max_model(ann_max, GMST):\n",
    "    ' Remove the max value from region, and corresponding GMST value '\n",
    "    ann_max_new = []\n",
    "    GMST_new = []\n",
    "    for ens in np.arange(np.shape(ann_max)[0]):\n",
    "        ann_max_new.append(np.delete(ann_max[ens], np.abs(ann_max[ens] - np.max(ann_max[ens])).argmin()))\n",
    "        GMST_new.append(np.delete(GMST, np.abs(ann_max[ens] - np.max(ann_max[ens])).argmin()))\n",
    "    return ann_max_new, GMST_new\n",
    "\n",
    "def calc_fit(data, GMST):\n",
    "    # data & GMST must be same shape\n",
    "    A, B = np.shape(data)\n",
    "    offset = []\n",
    "    model = np.reshape(data, [A*B])\n",
    "    gmst = np.reshape(GMST, [A*B])\n",
    "    a, b = np.polyfit(gmst, model, 1)\n",
    "    return a, b\n",
    "\n",
    "def detrend(data, gm, a, b, enssz):\n",
    "    A, B = np.shape(data)\n",
    "    offset_data = []\n",
    "    actual = data\n",
    "    predicted = np.reshape(gm*a+b, [enssz, numyrs])\n",
    "    offset = actual-predicted+(1*a+b) #for a GMST of 1C\n",
    "    return offset\n",
    "\n",
    "#Where the GEVs are fit!\n",
    "def return_period(GEV_data, extreme):\n",
    "    shape, loc, scale = gev.fit(GEV_data) # EVT distribution\n",
    "    x_val = np.linspace(np.min(GEV_data)-.5, np.max(GEV_data)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    chance = []\n",
    "    for i, _ in enumerate(dist_pdf):\n",
    "        P = []\n",
    "        for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "        chance.append(sum(P)*100)\n",
    "    x = chance[np.abs(x_val - extreme).argmin()] # chance of observed max\n",
    "    if x == 0:\n",
    "        result = np.nan\n",
    "    else:\n",
    "        result = 100.*1/x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust ERA5, MERRA2, and JRA55 annual-max data to a GMST of 1C\n",
    "#This prepares the way for daily data to be adjusted (which is done in Matlab)\n",
    "#Runtime 3 sec\n",
    "for loop in range(0,2):\n",
    "    if loop==0:\n",
    "        var='tw';\n",
    "    elif loop==1:\n",
    "        var='t';\n",
    "        \n",
    "    era5annmax=np.loadtxt(maindatadir+'era5output_'+var+'_regions.txt',delimiter=',').reshape((numregs,numyrs));\n",
    "    merra2annmax=np.loadtxt(maindatadir+'merra2output_'+var+'_regions.txt',delimiter=',').reshape((numregs,numyrs));\n",
    "    jra55annmax=np.loadtxt(maindatadir+'jra55output_'+var+'_regions.txt',delimiter=',').reshape((numregs,numyrs));\n",
    "    era5adjfactor=np.zeros((numregs,numyrs));\n",
    "    merra2adjfactor=np.zeros((numregs,numyrs));\n",
    "    jra55adjfactor=np.zeros((numregs,numyrs));\n",
    "    for reg in range(numregs):\n",
    "        a,b=np.polyfit(GMST,era5annmax[reg,:],1); # ERA5 annual max for this region versus GMST    \n",
    "        #Detrend\n",
    "        fittogmst_era5 = np.asarray(GMST)*a+b;\n",
    "        data_era5_adj = era5annmax[reg,:]-fittogmst_era5+(1*a+b) #for a GMST of 1C\n",
    "        era5adjfactor[reg,:]=data_era5_adj-era5annmax[reg,:]; #for transferring to Matlab to then adjust daily values\n",
    "\n",
    "\n",
    "        a,b=np.polyfit(GMST[20:],merra2annmax[reg,20:],1); # MERRA2 annual max for this region versus GMST   \n",
    "        #Detrend\n",
    "        fittogmst_merra2 = np.asarray(GMST[20:])*a+b;\n",
    "        data_merra2_adj = merra2annmax[reg,20:]-fittogmst_merra2+(1*a+b) #for a GMST of 1C\n",
    "        merra2adjfactor[reg,20:]=data_merra2_adj-merra2annmax[reg,20:]; #for transferring to Matlab to then adjust daily values\n",
    "        \n",
    "        \n",
    "        a,b=np.polyfit(GMST,jra55annmax[reg,:],1); # JRA55 annual max for this region versus GMST   \n",
    "        #Detrend\n",
    "        fittogmst_jra55 = np.asarray(GMST)*a+b;\n",
    "        data_jra55_adj = jra55annmax[reg,:]-fittogmst_jra55+(1*a+b) #for a GMST of 1C\n",
    "        jra55adjfactor[reg,:]=data_jra55_adj-jra55annmax[reg,:]; #for transferring to Matlab to then adjust daily values\n",
    "\n",
    "        \n",
    "    era5adjfactor[era5adjfactor == 0] =np.nan;\n",
    "    merra2adjfactor[merra2adjfactor == 0] =np.nan;\n",
    "    jra55adjfactor[jra55adjfactor == 0] =np.nan;\n",
    "\n",
    "    np.savetxt(maindatadir+\"era5adjfactors_\"+var+\".csv\",era5adjfactor,delimiter=\",\",fmt='%10.2f');\n",
    "    np.savetxt(maindatadir+\"merra2adjfactors_\"+var+\".csv\",merra2adjfactor,delimiter=\",\",fmt='%10.2f');\n",
    "    np.savetxt(maindatadir+\"jra55adjfactors_\"+var+\".csv\",jra55adjfactor,delimiter=\",\",fmt='%10.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af123e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29b5f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust model annual-max data to a GMST of 1C\n",
    "#This prepares the way for daily data to be adjusted (which is done in Matlab)\n",
    "#Runtime 5 sec\n",
    "for loop in range(0,1):\n",
    "        \n",
    "    myrs=60; \n",
    "        \n",
    "    canesm5annmax=np.loadtxt(maindatadir+'canesm5output_regions.txt',delimiter=',').reshape((canesm5_enssz,numregs,numyrs));\n",
    "    miroc6annmax=np.loadtxt(maindatadir+'miroc6output_regions.txt',delimiter=',').reshape((miroc6_enssz,numregs,numyrs));\n",
    "    mpigeannmax=np.loadtxt(maindatadir+'mpigeoutput_regions.txt',delimiter=',').reshape((mpige_enssz,numregs,numyrs));\n",
    "    canesm5adjfactor=np.zeros((canesm5_enssz,numregs,numyrs));\n",
    "    miroc6adjfactor=np.zeros((miroc6_enssz,numregs,numyrs));\n",
    "    mpigeadjfactor=np.zeros((mpige_enssz,numregs,numyrs));\n",
    "    for reg in range(numregs):\n",
    "        for ensmem in range(0,canesm5_enssz):\n",
    "            a,b=np.polyfit(GMST,canesm5annmax[ensmem,reg,:],1); # CanESM5 annual max for this region versus GMST    \n",
    "            #Detrend\n",
    "            fittogmst_canesm5 = np.asarray(GMST)*a+b;\n",
    "            data_canesm5_adj = canesm5annmax[ensmem,reg,:]-fittogmst_canesm5+(1*a+b) #for a GMST of 1C\n",
    "            canesm5adjfactor[ensmem,reg,:]=data_canesm5_adj-canesm5annmax[ensmem,reg,:]; #for xfer to Matlab\n",
    "\n",
    "        for ensmem in range(0,miroc6_enssz):\n",
    "            a,b=np.polyfit(GMST[20:],miroc6annmax[ensmem,reg,20:],1); # MIROC6 annual max for this region versus GMST   \n",
    "            #Detrend\n",
    "            fittogmst_miroc6 = np.asarray(GMST[20:])*a+b;\n",
    "            data_miroc6_adj = miroc6annmax[ensmem,reg,20:]-fittogmst_miroc6+(1*a+b) #for a GMST of 1C\n",
    "            miroc6adjfactor[ensmem,reg,20:]=data_miroc6_adj-miroc6annmax[ensmem,reg,20:]; #for xfer to Matlab\n",
    "\n",
    "        for ensmem in range(0,mpige_enssz):\n",
    "            a,b=np.polyfit(GMST,mpigeannmax[ensmem,reg,:],1); # MPI-GE annual max for this region versus GMST   \n",
    "            #Detrend\n",
    "            fittogmst_mpige = np.asarray(GMST)*a+b;\n",
    "            data_mpige_adj = mpigeannmax[ensmem,reg,:]-fittogmst_mpige+(1*a+b) #for a GMST of 1C\n",
    "            mpigeadjfactor[ensmem,reg,:]=data_mpige_adj-mpigeannmax[ensmem,reg,:]; #for xfer to Matlab\n",
    "\n",
    "        \n",
    "    canesm5adjfactor[canesm5adjfactor == 0] =np.nan;\n",
    "    miroc6adjfactor[miroc6adjfactor == 0] =np.nan;\n",
    "    mpigeadjfactor[mpigeadjfactor == 0] =np.nan;\n",
    "\n",
    "    np.savetxt(maindatadir+\"canesm5adjfactors_tw.csv\",canesm5adjfactor.flatten(order='F'),delimiter=\",\",fmt='%10.2f');\n",
    "    np.savetxt(maindatadir+\"miroc6adjfactors_tw.csv\",miroc6adjfactor.flatten(order='F'),delimiter=\",\",fmt='%10.2f');\n",
    "    np.savetxt(maindatadir+\"mpigeadjfactors_tw.csv\",mpigeadjfactor.flatten(order='F'),delimiter=\",\",fmt='%10.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "460f8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Troubleshooting (of the cell below) for a selected region\n",
    "troubleshoot=0;\n",
    "if troubleshoot==1:\n",
    "    reg=160;\n",
    "    ann_max = modelannmax[:,reg,:]; #2D array, with data for each ens mem and year\n",
    "    a, b = calc_fit(ann_max, np.tile(GMST, enssz)) # annual max for this region versus GMST\n",
    "    offset = detrend(ann_max, np.tile(GMST, enssz), a, b,enssz)\n",
    "    ann_max_new_detrend, GMST_new_detrend = remove_max_model(offset, GMST)\n",
    "\n",
    "    max_3yr=np.zeros((enssz,numblocks)); #2D array, with data for each ens mem and 3-year block maxima\n",
    "    for ens in np.arange(enssz):\n",
    "        for i in range(blsz-1,numyrs,blsz):\n",
    "            max_3yr[ens,int((i+1)/blsz-1)]=np.max(ann_max[ens,i-(blsz-1):i+1]);\n",
    "\n",
    "    max_1yr = ann_max_new_detrend #detrended annual maxes\n",
    "    model_extremes = np.max(offset, axis=1) #physically modeled extremes\n",
    "    ret_per_1yr = [];ret_per_3yr = [];\n",
    "\n",
    "    #Fit GEV (based on annual maxima)\n",
    "    for ens in np.arange(enssz):\n",
    "        ret_per_1yr.append(return_period(max_1yr[ens], model_extremes[ens]))\n",
    "    my_impossible_count=(sum(np.isnan(x) for x in ret_per_1yr))\n",
    "\n",
    "    #Fit GEV using 5-year block maxima instead\n",
    "    blockmax_3yr=np.zeros((enssz,numblocks));\n",
    "    for ens in np.arange(enssz):\n",
    "        for i in range(blsz-1,numyrs,blsz):\n",
    "            blockmax_3yr[ens,int((i+1)/blsz-1)]=np.max(max_1yr[ens][i-(blsz-1):i+1]);\n",
    "\n",
    "        ret_per_3yr.append(return_period(blockmax_3yr[ens], model_extremes[ens]))\n",
    "    my_impossible_count_3yr=(sum(np.isnan(x) for x in ret_per_3yr))\n",
    "\n",
    "\n",
    "    #Place in a separate cell for serious troubleshooting\n",
    "    ens=0\n",
    "    GEV_data=blockmax_3yr[ens]\n",
    "    extreme=model_extremes[ens]\n",
    "\n",
    "    shape, loc, scale = gev.fit(GEV_data) # EVT distribution\n",
    "    x_val = np.linspace(np.min(GEV_data)-.5, np.max(GEV_data)+2, 1000)\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    chance = []\n",
    "    for i, _ in enumerate(dist_pdf):\n",
    "        P = []\n",
    "        for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "        chance.append(sum(P)*100)\n",
    "    x = chance[np.abs(x_val - extreme).argmin()] # chance of observed max\n",
    "    if x == 0:\n",
    "        result = np.nan\n",
    "    else:\n",
    "        result = 100.*1/x\n",
    "\n",
    "    np.round(result)\n",
    "\n",
    "    #plt.plot(ret_per_3yr)\n",
    "\n",
    "\n",
    "    #Evaluate GEV and return periods across full ensemble\n",
    "    #model_forGEV = np.sort(np.reshape(ann_max.data, [numyrs*enssz,]))[:-1] #ann maxes including overall maximum\n",
    "    #model_extreme = np.max(np.reshape(ann_max.data, [numyrs*enssz,])); #maximum\n",
    "    #my_ret_per_full=np.round(return_period(model_forGEV, model_extreme))\n",
    "\n",
    "    #model_forGEV_3yr = np.sort(np.reshape(max_3yr.data, [numblocks*enssz,]))[:-1] #everything but maximum\n",
    "    #model_extreme_3yr = np.max(np.reshape(max_3yr.data, [numblocks*enssz,])); #maximum\n",
    "    #my_ret_per_full_3yr=np.round(return_period(model_forGEV_3yr, model_extreme_3yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c05f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                          Type              Data/Info\n",
      "-------------------------------------------------------------\n",
      "GMST                              list              n=63\n",
      "GMST_new                          ndarray           62: 62 elems, type `float64`, 496 bytes\n",
      "GMST_since1981                    list              n=43\n",
      "GMST_yr                           ndarray           63: 63 elems, type `int64`, 504 bytes\n",
      "LogNorm                           type              <class 'matplotlib.colors.LogNorm'>\n",
      "P                                 list              n=0\n",
      "RegularGridInterpolator           type              <class 'scipy.interpolate<...>RegularGridInterpolator'>\n",
      "a                                 float64           0.0\n",
      "abs_max                           function          <function abs_max at 0x17587e660>\n",
      "actual                            float64           19.024\n",
      "add_season_membership             function          <function add_season_membership at 0x11eb8c400>\n",
      "adjust_obs                        function          <function adjust_obs at 0x17587e700>\n",
      "adjust_obs_1981                   function          <function adjust_obs_1981 at 0x178d8d3a0>\n",
      "ann_max                           ndarray           63: 63 elems, type `float64`, 504 bytes\n",
      "ann_max_new                       ndarray           62: 62 elems, type `float64`, 496 bytes\n",
      "b                                 float64           0.0\n",
      "bootstrap_uncertainties           function          <function bootstrap_uncertainties at 0x17587e340>\n",
      "canesm5_enssz                     int               50\n",
      "cart                              module            <module 'cartopy' from '/<...>ges/cartopy/__init__.py'>\n",
      "ccrs                              module            <module 'cartopy.crs' fro<...>packages/cartopy/crs.py'>\n",
      "chance                            list              n=1000\n",
      "cm                                module            <module 'matplotlib.cm' f<...>ckages/matplotlib/cm.py'>\n",
      "coarserregs                       ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "colin                             int               1\n",
      "convertvalsformapping             int               0\n",
      "cube_to_array                     function          <function cube_to_array at 0x17587dc60>\n",
      "dist_pdf                          ndarray           1000: 1000 elems, type `float64`, 8000 bytes\n",
      "domainprep                        int               1\n",
      "domasking                         int               0\n",
      "each                              int64             236\n",
      "equalise_attributes               function          <function equalise_attributes at 0x11eb85a80>\n",
      "era5regannmax_t                   ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "era5regannmax_tw                  ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "fnamepart                         str               tw_jra55\n",
      "gev                               genextreme_gen    <scipy.stats._continuous_<...>en object at 0x14d49ad50>\n",
      "glob                              module            <module 'glob' from '/opt<...>/lib/python3.11/glob.py'>\n",
      "how_much_higher                   function          <function how_much_higher at 0x17587e5c0>\n",
      "i                                 int               999\n",
      "icc                               module            <module 'iris.coord_categ<...>coord_categorisation.py'>\n",
      "iplt                              module            <module 'iris.plot' from <...>e-packages/iris/plot.py'>\n",
      "iris                              module            <module 'iris' from '/opt<...>ckages/iris/__init__.py'>\n",
      "jra55regannmax_t                  ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "jra55regannmax_tw                 ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "lats                              DataArray         <xarray.DataArray 'lat' (<...>th\\n    axis:           Y\n",
      "load_annmax                       function          <function load_annmax at 0x17587e8e0>\n",
      "loc                               float64           18.92703223023463\n",
      "lons                              DataArray         <xarray.DataArray 'lon' (<...>st\\n    axis:           X\n",
      "loop                              int               3\n",
      "maindatadir                       str               /Volumes/ExternalDriveD/Thompson_savedarrays/\n",
      "maket23fig2                       int               0\n",
      "maket23fig3                       int               0\n",
      "maket23fig4                       int               0\n",
      "mask_regs                         ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "mask_regs_t                       ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "mask_regs_tw                      ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "maskingvs                         str               jra55\n",
      "max_val                           float64           21.334760190167927\n",
      "miroc6_enssz                      int               10\n",
      "modelnames                        list              n=3\n",
      "mpige_enssz                       int               50\n",
      "mpl_cm                            module            <module 'matplotlib.cm' f<...>ckages/matplotlib/cm.py'>\n",
      "nc                                module            <module 'netCDF4' from '/<...>ges/netCDF4/__init__.py'>\n",
      "np                                module            <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "numregs                           int               237\n",
      "numregs_ant                       int               21\n",
      "numregs_noant                     int               216\n",
      "numyrs                            int               63\n",
      "obs_max_ret_per                   function          <function obs_max_ret_per at 0x17587eca0>\n",
      "obs_max_ret_per_removeevent       function          <function obs_max_ret_per<...>moveevent at 0x399369800>\n",
      "offset                            list              n=63\n",
      "offset_100                        function          <function offset_100 at 0x17587dee0>\n",
      "offset_full                       list              n=63\n",
      "offset_higher                     function          <function offset_higher at 0x17587ede0>\n",
      "offset_higher_removeevent         function          <function offset_higher_r<...>moveevent at 0x399369a80>\n",
      "offset_maxval                     function          <function offset_maxval at 0x17587ec00>\n",
      "offset_new                        list              n=62\n",
      "one_in_hundred                    function          <function one_in_hundred at 0x17587ea20>\n",
      "one_in_tenthousand                function          <function one_in_tenthousand at 0x17587e520>\n",
      "orignumlats                       int               4320\n",
      "orignumlons                       int               8640\n",
      "plot_EVT                          function          <function plot_EVT at 0x17587e7a0>\n",
      "plot_data_GMST                    function          <function plot_data_GMST at 0x17587eac0>\n",
      "plot_gev                          function          <function plot_gev at 0x17587e480>\n",
      "plot_points                       function          <function plot_points at 0x17587e3e0>\n",
      "plt                               module            <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predicted                         float64           19.308796639022493\n",
      "r                                 int               236\n",
      "random                            module            <module 'random' from '/o<...>ib/python3.11/random.py'>\n",
      "reg                               int               116\n",
      "reg_mask                          list              n=237\n",
      "reg_mask_t                        list              n=237\n",
      "regannmax                         ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "regcenterlats_noant               ndarray           216: 216 elems, type `float64`, 1728 bytes\n",
      "regcenterlats_tmp                 list              n=237\n",
      "regcenterlons_noant               ndarray           216: 216 elems, type `float64`, 1728 bytes\n",
      "regcenterlons_tmp                 list              n=237\n",
      "regcenterpoints                   ndarray           237x2: 474 elems, type `float64`, 3792 bytes\n",
      "region                            int               236\n",
      "region_abs                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_abs_t                      ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_actual                     ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_actual_t                   ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_fp                         str               /Volumes/ExternalDriveD/T<...>-1_4-1-0_000000-000000.nc\n",
      "region_mask                       ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_mask_t                     ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ord                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ord_t                      ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper                     ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper_t                   ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper_withtopevents       ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "regords_noant                     list              n=237\n",
      "regrid                            function          <function regrid at 0x17587eb60>\n",
      "regs_in_ant                       ndarray           21: 21 elems, type `int64`, 168 bytes\n",
      "remove_max                        function          <function remove_max at 0x17587e980>\n",
      "rerunmodelcomp                    int               0\n",
      "result                            float64           211.9292712012497\n",
      "result_new                        int               99999\n",
      "return_levels_plot                function          <function return_levels_plot at 0x17587e2a0>\n",
      "scale                             float64           0.7872061373060784\n",
      "scipy                             module            <module 'scipy' from '/op<...>kages/scipy/__init__.py'>\n",
      "shape                             float64           0.3406865582093087\n",
      "sps                               module            <module 'scipy.stats' fro<...>scipy/stats/__init__.py'>\n",
      "sys                               module            <module 'sys' (built-in)>\n",
      "ticker                            module            <module 'matplotlib.ticke<...>es/matplotlib/ticker.py'>\n",
      "time_slice                        function          <function time_slice at 0x17587dda0>\n",
      "vals_abs_noant                    list              n=237\n",
      "vals_abs_noant_t                  list              n=237\n",
      "vals_actual_noant                 list              n=237\n",
      "vals_actual_noant_t               list              n=237\n",
      "vals_retper_noant                 list              n=237\n",
      "vals_retper_noant_t               list              n=237\n",
      "vals_retper_noant_withtopevents   list              n=237\n",
      "var                               str               tw_jra55\n",
      "x                                 float64           0.0\n",
      "x_val                             ndarray           1000: 1000 elems, type `float64`, 8000 bytes\n",
      "xr                                module            <module 'xarray' from '/o<...>ages/xarray/__init__.py'>\n",
      "y1                                int               1961\n",
      "y2                                int               2023\n",
      "year_max                          function          <function year_max at 0x1098251c0>\n",
      "year_max_adjust                   function          <function year_max_adjust at 0x178d8d6c0>\n",
      "year_max_adjust_1981              function          <function year_max_adjust_1981 at 0x1098258a0>\n",
      "year_max_multiple_adjust          function          <function year_max_multip<...>le_adjust at 0x109825800>\n",
      "year_max_multiple_adjust_1981     function          <function year_max_multip<...>just_1981 at 0x109825a80>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfe4ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes percent of model ensemble members showing record events outside the GEV fit\n",
    "#Runtime: about 45 min for CanESM5, 10 min for MIROC6, 25 min for MPI\n",
    "#Once run, results can be reloaded\n",
    "if rerunmodelcomp==1:\n",
    "    for model in range(0,3): #default is 0,3\n",
    "        if model==0:\n",
    "            enssz=canesm5_enssz;mname='canesm5';\n",
    "            impossible_pct_canesm5=[];ret_per_full_canesm5=[];\n",
    "            impossible_pct_3yr_canesm5=[];ret_per_full_3yr_canesm5=[];\n",
    "        elif model==1:\n",
    "            enssz=miroc6_enssz;mname='miroc6';\n",
    "            impossible_pct_miroc6=[];ret_per_full_miroc6=[];\n",
    "            impossible_pct_3yr_miroc6=[];ret_per_full_3yr_miroc6=[];\n",
    "        elif model==2:\n",
    "            enssz=mpige_enssz;mname='mpige';\n",
    "            impossible_pct_mpige=[];ret_per_full_mpige=[];\n",
    "            impossible_pct_3yr_mpige=[];ret_per_full_3yr_mpige=[];\n",
    "\n",
    "        impossible_count=[];ret_per_full=[];\n",
    "        impossible_count_3yr=[];ret_per_full_3yr=[];\n",
    "        blsz=3; #alternative (to annual) block size, in years\n",
    "        numblocks=int(numyrs/blsz);\n",
    "\n",
    "        modelannmax=np.loadtxt(maindatadir+mname+'output_regions.txt',delimiter=',').reshape((enssz,numregs,numyrs));\n",
    "        \n",
    "        for reg in range(numregs):\n",
    "            ann_max = modelannmax[:,reg,:]; #2D array, with data for each ens mem and year\n",
    "            a, b = calc_fit(ann_max, np.tile(GMST, enssz)) # annual max for this region versus GMST\n",
    "            offset = detrend(ann_max, np.tile(GMST, enssz), a, b,enssz)\n",
    "            ann_max_new_detrend, GMST_new_detrend = remove_max_model(offset, GMST)\n",
    "            \n",
    "            max_3yr=np.zeros((enssz,numblocks)); #2D array, with data for each ens mem and 3-year block maxima\n",
    "            for ens in np.arange(enssz):\n",
    "                for i in range(blsz-1,numyrs,blsz):\n",
    "                    max_3yr[ens,int((i+1)/blsz-1)]=np.max(ann_max[ens,i-(blsz-1):i+1]);\n",
    "            \n",
    "            model_forGEV = ann_max_new_detrend #detrended annual maxes\n",
    "            model_extremes = np.max(offset, axis=1) #physically modeled extremes\n",
    "            ret_per_1yr = [];ret_per_3yr = [];\n",
    "            \n",
    "            #Fit GEV (based on annual maxima)\n",
    "            for ens in np.arange(enssz):\n",
    "                ret_per_1yr.append(return_period(model_forGEV[ens], model_extremes[ens]))\n",
    "            impossible_count.append(sum(np.isnan(x) for x in ret_per_1yr))\n",
    "            \n",
    "            #Fit GEV using 5-year block maxima instead\n",
    "            blockmax=np.zeros((enssz,numblocks));\n",
    "            for ens in np.arange(enssz):\n",
    "                for i in range(blsz-1,numyrs,blsz):\n",
    "                    blockmax[ens,int((i+1)/blsz-1)]=np.max(model_forGEV[ens][i-(blsz-1):i+1]);\n",
    "                    \n",
    "                ret_per_3yr.append(return_period(blockmax[ens], model_extremes[ens]))\n",
    "            impossible_count_3yr.append(sum(np.isnan(x) for x in ret_per_3yr))\n",
    "            \n",
    "            \n",
    "            #Evaluate GEV and return periods across full ensemble\n",
    "            model_forGEV = np.sort(np.reshape(ann_max.data, [numyrs*enssz,]))[:-1] #ann maxes including overall maximum\n",
    "            model_extreme = np.max(np.reshape(ann_max.data, [numyrs*enssz,])); #maximum\n",
    "            ret_per_full.append(np.round(return_period(model_forGEV, model_extreme)))\n",
    "            #print(reg, impossible_count[-1], ret_per_full[-1])\n",
    "            \n",
    "            model_forGEV_3yr = np.sort(np.reshape(max_3yr.data, [numblocks*enssz,]))[:-1] #everything but maximum\n",
    "            model_extreme_3yr = np.max(np.reshape(max_3yr.data, [numblocks*enssz,])); #maximum\n",
    "            ret_per_full_3yr.append(np.round(return_period(model_forGEV_3yr, model_extreme_3yr)))\n",
    "\n",
    "            \n",
    "        # For all regions, adjust number to be a percentage of ens members outside GEV fit\n",
    "        multiplyby=100/enssz;\n",
    "        impossible_pct=[x*multiplyby for x in impossible_count];\n",
    "        impossible_pct_3yr=[x*multiplyby for x in impossible_count_3yr];\n",
    "\n",
    "        if model==0:\n",
    "            impossible_pct_canesm5=impossible_pct;ret_per_full_canesm5=ret_per_full;\n",
    "            impossible_pct_3yr_canesm5=impossible_pct_3yr;ret_per_full_3yr_canesm5=ret_per_full_3yr;\n",
    "            \n",
    "            np.savetxt(maindatadir+\"impossiblepct_canesm5.csv\",np.array(impossible_pct_canesm5),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_canesm5.csv\",np.array(ret_per_full_canesm5),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"impossiblepct_3yr_canesm5.csv\",np.array(impossible_pct_3yr_canesm5),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_3yr_canesm5.csv\",np.array(ret_per_full_3yr_canesm5),delimiter=\",\",fmt='%10.2f')\n",
    "        elif model==1:\n",
    "            impossible_pct_miroc6=impossible_pct;ret_per_full_miroc6=ret_per_full;\n",
    "            impossible_pct_3yr_miroc6=impossible_pct_3yr;ret_per_full_3yr_miroc6=ret_per_full_3yr;\n",
    "            \n",
    "            np.savetxt(maindatadir+\"impossiblepct_miroc6.csv\",np.array(impossible_pct_miroc6),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_miroc6.csv\",np.array(ret_per_full_miroc6),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"impossiblepct_3yr_miroc6.csv\",np.array(impossible_pct_3yr_miroc6),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_3yr_miroc6.csv\",np.array(ret_per_full_3yr_miroc6),delimiter=\",\",fmt='%10.2f')\n",
    "        elif model==2:\n",
    "            impossible_pct_mpige=impossible_pct;ret_per_full_mpige=ret_per_full;\n",
    "            impossible_pct_3yr_mpige=impossible_pct_3yr;ret_per_full_3yr_mpige=ret_per_full_3yr;\n",
    "            \n",
    "            np.savetxt(maindatadir+\"impossiblepct_mpige.csv\",np.array(impossible_pct_mpige),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_mpige.csv\",np.array(ret_per_full_mpige),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"impossiblepct_3yr_mpige.csv\",np.array(impossible_pct_3yr_mpige),delimiter=\",\",fmt='%10.2f')\n",
    "            np.savetxt(maindatadir+\"retperfull_3yr_mpige.csv\",np.array(ret_per_full_3yr_mpige),delimiter=\",\",fmt='%10.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d68201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert vals to regional data for mapping (2 min)\n",
    "#THIS AND THE CELL BELOW ARE NO LONGER NEEDED BECAUSE THE FIGURE IS CREATED IN MATLAB INSTEAD\n",
    "if convertvalsformapping==1:\n",
    "    impossible_pct_canesm5=np.loadtxt(maindatadir+\"impossiblepct_canesm5.csv\");\n",
    "    impossible_pct_miroc6=np.loadtxt(maindatadir+\"impossiblepct_miroc6.csv\");\n",
    "    impossible_pct_mpige=np.loadtxt(maindatadir+\"impossiblepct_mpige.csv\");\n",
    "    ret_per_full_canesm5=np.loadtxt(maindatadir+\"retperfull_canesm5.csv\");\n",
    "    ret_per_full_miroc6=np.loadtxt(maindatadir+\"retperfull_miroc6.csv\");\n",
    "    ret_per_full_mpige=np.loadtxt(maindatadir+\"retperfull_mpige.csv\");\n",
    "\n",
    "    impossiblearr_canesm5=region_ds.region;impossiblearr_miroc6=region_ds.region;\n",
    "    impossiblearr_mpige=region_ds.region;\n",
    "    retperarr_canesm5=region_ds.region;retperarr_miroc6=region_ds.region;\n",
    "    retperarr_mpige=region_ds.region;\n",
    "    for r in range(numregs):\n",
    "        impossiblearr_canesm5=impossiblearr_canesm5.where(region_ds.region.values!=r,impossible_pct_canesm5[r])\n",
    "        impossiblearr_miroc6=impossiblearr_miroc6.where(region_ds.region.values!=r,impossible_pct_miroc6[r])\n",
    "        impossiblearr_mpige=impossiblearr_mpige.where(region_ds.region.values!=r,impossible_pct_mpige[r])\n",
    "        retperarr_canesm5=retperarr_canesm5.where(region_ds.region.values!=r,ret_per_full_canesm5[r])\n",
    "        retperarr_miroc6=retperarr_miroc6.where(region_ds.region.values!=r,ret_per_full_miroc6[r])\n",
    "        retperarr_mpige=retperarr_mpige.where(region_ds.region.values!=r,ret_per_full_mpige[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3c56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000757f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create map paralleling Thompson et al. 2023 Fig 4\n",
    "#Runtime: 3 min\n",
    "if maket23fig4==1:\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(20., 12.), dpi=80, num=None, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    for model in range(0,3):\n",
    "        if model==0:\n",
    "            impossiblearr=impossiblearr_canesm5;retperarr=retperarr_canesm5;\n",
    "            ret_per_full=ret_per_full_canesm5;impossible_pct=impossible_pct_canesm5;\n",
    "            mnamecap='CanESM5';leftlabel='a';rightlabel='b';\n",
    "        elif model==1:\n",
    "            impossiblearr=impossiblearr_miroc6;retperarr=retperarr_miroc6;\n",
    "            ret_per_full=ret_per_full_miroc6;impossible_pct=impossible_pct_miroc6;\n",
    "            mnamecap='MIROC6';leftlabel='c';rightlabel='d';\n",
    "        elif model==2:\n",
    "            impossiblearr=impossiblearr_mpige;retperarr=retperarr_mpige;\n",
    "            ret_per_full=ret_per_full_mpige;impossible_pct=impossible_pct_mpige;\n",
    "            mnamecap='MPI-ESM';leftlabel='e';rightlabel='f';\n",
    "\n",
    "        row=model;\n",
    "\n",
    "        axis_font = {'fontname':'Arial', 'size':'14'};\n",
    "\n",
    "        # left subplot: impossible count for this model\n",
    "        levels=[0, 10, 20, 30, 40, 50, 60]\n",
    "        c = axs[row,0].contourf(lons,lats,impossiblearr,9,transform=ccrs.PlateCarree(),\n",
    "                            cmap=mpl_cm.get_cmap('brewer_PuRd_09'), linestyle='solid',\n",
    "                            levels=levels)\n",
    "        cbar = plt.colorbar(c, shrink=0.7, ax=axs[row,0])\n",
    "        cbar.set_label('% of ensemble members')\n",
    "        cbar.outline.set_linewidth(0.5)\n",
    "        axs[row,0].set_title(mnamecap+': Exceptional ensembles')\n",
    "        axs[row,0].text(-190, 80, leftlabel,**axis_font);axs[row,0].coastlines();axs[row,0].set_ylim([-60, 90])\n",
    "\n",
    "        # right subplot: ensemble return periods for this model\n",
    "        from matplotlib import ticker, cm\n",
    "        e = axs[row,1].contourf(lons,lats,impossiblearr,11,transform=ccrs.PlateCarree(),\n",
    "                            colors='r',vmin=-10, vmax=1000) # might need adjusting\n",
    "        levels=np.logspace(np.log10(10),np.log10(1000000000),5)\n",
    "        d = axs[row,1].contourf(lons,lats,retperarr,6,transform=ccrs.PlateCarree(),\n",
    "                            levels=levels, locator=ticker.LogLocator(base=10),\n",
    "                            cmap=mpl_cm.get_cmap('Blues'), linestyle='solid',extend='max')\n",
    "        cbar = plt.colorbar(d, shrink=0.7, ax = axs[row,1], ticks=levels)\n",
    "        cbar.set_label('Years')\n",
    "        cbar.outline.set_linewidth(0.5)\n",
    "        axs[row,1].set_title(mnamecap+': Return periods')\n",
    "        axs[row,1].text(-190, 80, rightlabel,**axis_font);axs[row,1].coastlines();axs[row,1].set_ylim([-60, 90])\n",
    "        axs[row,1].text(-170, -50, 'Exceptional', fontsize = 10, \n",
    "                 bbox = dict(facecolor = 'red', alpha = 0.5))\n",
    "\n",
    "        # Delete the Antarctic regions\n",
    "        regs_in_ant = np.arange(170, 191)\n",
    "        for each in regs_in_ant:\n",
    "            ret_per_full.tolist().pop(each)\n",
    "            impossible_pct.tolist().pop(each)\n",
    "\n",
    "        # Percentages for this model\n",
    "        imp = np.round(np.mean(np.asarray(impossible_pct)),2);\n",
    "        full=np.round(sum(np.isnan(x) for x in ret_per_full)/numregs_noant*100,2);\n",
    "\n",
    "        if model==0:\n",
    "            imp_canesm5=imp;full_canesm5=full;\n",
    "        elif model==1:\n",
    "            imp_miroc6=imp;full_miroc6=full;\n",
    "        elif model==2:\n",
    "            imp_mpige=imp;full_mpige=full;\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('modelsummary_t23f4.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85102488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of ensemble members showing record events outside the GEV fit\n",
    "#UNFINISHED -- USE CODE JUST ABOVE\n",
    "#Runtime 5 sec\n",
    "dothis=0;\n",
    "if dothis==1:\n",
    "    shapearr=np.zeros((numregs,));locarr=np.zeros((numregs,));scalearr=np.zeros((numregs,));\n",
    "    thispdf=np.zeros((numregs,10000));\n",
    "\n",
    "    era5data=np.loadtxt(maindatadir+'tw_regannmax_era5_adj.txt',delimiter=',').reshape((numregs,numyrs));\n",
    "    canesm5data=np.loadtxt(maindatadir+'tw_regoverallmax_canesm5_adj.txt',delimiter=',').reshape((canesm5_enssz,numregs)); \n",
    "    miroc6data=np.loadtxt(maindatadir+'tw_regoverallmax_miroc6_adj.txt',delimiter=',').reshape((miroc6_enssz,numregs)); \n",
    "    mpigedata=np.loadtxt(maindatadir+'tw_regoverallmax_mpige_adj.txt',delimiter=',').reshape((mpige_enssz,numregs));\n",
    "\n",
    "    pctexceeding_canesm5=np.zeros((numregs,))\n",
    "    pctexceeding_miroc6=np.zeros((numregs,))\n",
    "    pctexceeding_mpige=np.zeros((numregs,))\n",
    "\n",
    "    for reg in range(numregs):\n",
    "        ann_max_era5 = era5data[reg,:];\n",
    "        res = gev.fit(ann_max_era5); # EVT distribution from obs\n",
    "        shapearr[reg]=res[0];\n",
    "        locarr[reg]=res[1];\n",
    "        scalearr[reg]=res[2];\n",
    "\n",
    "        x_val = np.linspace(np.min(ann_max_era5)-3, np.max(ann_max_era5)+3, 10000)\n",
    "        tmp=gev.pdf(x_val, shapearr[reg], locarr[reg], scalearr[reg]);\n",
    "\n",
    "        #Max non-zero GEV value (Celsius) -- reminder, this is still based on ERA5 adjusted to a GMST of 1C\n",
    "        zeros=tmp[np.nonzero(tmp)]\n",
    "        maxnonzerogevval=x_val[np.shape(zeros)[0]-1];\n",
    "\n",
    "        #Percent of ensemble members exceeding the obs GEV fit\n",
    "        pctexceeding_canesm5[reg]=100*np.sum(canesm5data[:,reg]>maxnonzerogevval)/canesm5_enssz;\n",
    "        pctexceeding_miroc6[reg]=100*np.sum(miroc6data[:,reg]>maxnonzerogevval)/miroc6_enssz;\n",
    "        pctexceeding_mpige[reg]=100*np.sum(mpigedata[:,reg]>maxnonzerogevval)/mpige_enssz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b09c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaefed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosometroubleshooting=0;\n",
    "if dosometroubleshooting==1:\n",
    "    reg=233;var='tw';\n",
    "    ann_max = load_annmax(reg,var)\n",
    "    ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "    offset = []\n",
    "    a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "    for i, each in enumerate(ann_max_new):\n",
    "        actual = each\n",
    "        predicted = GMST_new[i]*a +b\n",
    "        offset.append(actual-predicted+(1*a+b))\n",
    "    #max_val = np.max(offset) #the maximum observed\n",
    "    shape, loc, scale = gev.fit(offset) # EVT distribution\n",
    "    x_val = np.linspace(np.min(offset)-.5, np.max(offset)+2, 1000)\n",
    "        #so e.g. for reg 51, which was most thoroughly troubleshooted, this pdf is defined from about 24.0 to 27.4 C\n",
    "    dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "    offset_full = []\n",
    "    for i, each in enumerate(ann_max):\n",
    "        actual = each\n",
    "        predicted = GMST[i]*a +b\n",
    "        offset_full.append(actual-predicted+(1*a+b))\n",
    "    max_val = np.max(offset_full)\n",
    "    chance = []\n",
    "    for i, _ in enumerate(dist_pdf):\n",
    "        P = []\n",
    "        for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "            P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "        chance.append(sum(P)*100)\n",
    "    x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "    if x == 0:\n",
    "        result = 99999\n",
    "    else:\n",
    "        result = 100.*1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More troubleshooting follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c787a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_in_hundred(myarr):\n",
    "shape, loc, scale = gev.fit(myarr)\n",
    "x_val = np.linspace(np.min(myarr)-.5, np.max((myarr))+2, 1000)\n",
    "#dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "#ret_lev, chance = return_levels_plot(dist_pdf, x_val)\n",
    "#return ret_lev[np.abs(np.asarray(chance)-1).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs_max_ret_per_removeevent(reg,var):\n",
    "reg=68;\n",
    "tmp_era5=np.loadtxt(maindatadir+'era5output_'+var+'_regions.txt',delimiter=',')[reg,:];\n",
    "tmp_jra55=np.loadtxt(maindatadir+'jra55output_'+var+'_regions.txt',delimiter=',')[reg,:];\n",
    "ann_max=(tmp_era5+tmp_jra55)/2;\n",
    "#ann_max = load_annmax(reg,var)\n",
    "ann_max_new, GMST_new = remove_max(ann_max, GMST)\n",
    "offset = []\n",
    "a, b = np.polyfit(GMST_new, ann_max_new, 1)\n",
    "for i, each in enumerate(ann_max_new):\n",
    "    actual = each\n",
    "    predicted = GMST_new[i]*a +b\n",
    "    offset.append(actual-predicted+(1*a+b)) #adjust for world with 1 deg of warming\n",
    "#max_val = np.max(offset) # Maximum observed\n",
    "shape, loc, scale = gev.fit(offset) # EVT distribution\n",
    "x_val = np.linspace(np.min(offset)-.5, np.max(offset)+2, 1000)\n",
    "dist_pdf = gev.pdf(x_val, shape, loc, scale)\n",
    "offset_full = []\n",
    "for i, each in enumerate(ann_max):\n",
    "    actual = each\n",
    "    predicted = GMST[i]*a +b\n",
    "    offset_full.append(actual-predicted+(1*a+b))\n",
    "max_val = np.max(offset_full)\n",
    "chance = []\n",
    "for i, _ in enumerate(dist_pdf):\n",
    "    P = []\n",
    "    for a, b in zip(dist_pdf[i:-1], dist_pdf[i+1:]):\n",
    "        P.append(((a+b) / 2) * (x_val[1] - x_val[0])) \n",
    "    chance.append(sum(P)*100)\n",
    "x = chance[np.abs(x_val - max_val).argmin()] # chance of observed max\n",
    "if x == 0:\n",
    "    result = 99999\n",
    "else:\n",
    "    result = 100.*1/x\n",
    "return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5regannmax_adj_tw=np.loadtxt(maindatadir+'era5output_tw_adj_regions.txt',delimiter=',');\n",
    "jra55regannmax_adj_tw=np.loadtxt(maindatadir+'jra55output_tw_adj_regions.txt',delimiter=',');\n",
    "oneinhundredval=np.zeros((numregs,));\n",
    "for reg in range(numregs):\n",
    "    era5arr=era5regannmax_adj_tw[reg,:];\n",
    "    jra55arr=jra55regannmax_adj_tw[reg,:];\n",
    "    myarr=(era5arr+jra55arr)/2;\n",
    "    myrec=np.max(myarr);  \n",
    "    oneinhundredval[reg]=one_in_hundred(myarr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regannmax=(era5regannmax_tw+jra55regannmax_tw)/2;\n",
    "vals_retper_noant = [] #return periods\n",
    "for each in np.arange(numregs):\n",
    "    vals_retper_noant.append(obs_max_ret_per_removeevent(each,var)) #Return periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa290ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18c723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a576c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                             Type              Data/Info\n",
      "----------------------------------------------------------------\n",
      "GMST                                 list              n=63\n",
      "GMST_new                             ndarray           62: 62 elems, type `float64`, 496 bytes\n",
      "GMST_since1981                       list              n=43\n",
      "GMST_yr                              ndarray           63: 63 elems, type `int64`, 504 bytes\n",
      "LogNorm                              type              <class 'matplotlib.colors.LogNorm'>\n",
      "RegularGridInterpolator              type              <class 'scipy.interpolate<...>RegularGridInterpolator'>\n",
      "a                                    float64           0.7623001584732692\n",
      "abs_max                              function          <function abs_max at 0x3016c28e0>\n",
      "actual                               float64           19.024\n",
      "add_season_membership                function          <function add_season_membership at 0x132760180>\n",
      "adjust_obs                           function          <function adjust_obs at 0x3016c2700>\n",
      "adjust_obs_1981                      function          <function adjust_obs_1981 at 0x16c386ca0>\n",
      "ann_max                              ndarray           63: 63 elems, type `float64`, 504 bytes\n",
      "ann_max_new                          ndarray           62: 62 elems, type `float64`, 496 bytes\n",
      "b                                    float64           18.416905453608766\n",
      "bootstrap_uncertainties              function          <function bootstrap_uncertainties at 0x3016c20c0>\n",
      "calc_fit                             function          <function calc_fit at 0x3016c0720>\n",
      "canesm5_enssz                        int               50\n",
      "cart                                 module            <module 'cartopy' from '/<...>ges/cartopy/__init__.py'>\n",
      "ccrs                                 module            <module 'cartopy.crs' fro<...>packages/cartopy/crs.py'>\n",
      "cm                                   module            <module 'matplotlib.cm' f<...>ckages/matplotlib/cm.py'>\n",
      "coarserregs                          ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "convertvalsformapping                int               0\n",
      "cube_to_array                        function          <function cube_to_array at 0x107a21760>\n",
      "detrend                              function          <function detrend at 0x3048a2e80>\n",
      "dist_pdf                             ndarray           1000: 1000 elems, type `float64`, 8000 bytes\n",
      "domainprep                           int               1\n",
      "domasking                            int               0\n",
      "each                                 float64           19.024\n",
      "equalise_attributes                  function          <function equalise_attributes at 0x132755800>\n",
      "era5arr                              ndarray           63: 63 elems, type `float64`, 504 bytes\n",
      "era5regannmax_adj_tw                 ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "era5regannmax_t                      ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "era5regannmax_tw                     ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "fnamepart                            str               tw_era5\n",
      "gev                                  genextreme_gen    <scipy.stats._continuous_<...>en object at 0x16b7106d0>\n",
      "glob                                 module            <module 'glob' from '/opt<...>/lib/python3.11/glob.py'>\n",
      "how_much_higher                      function          <function how_much_higher at 0x3016c2160>\n",
      "hundred_rec_diff                     ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "i                                    int               61\n",
      "icc                                  module            <module 'iris.coord_categ<...>coord_categorisation.py'>\n",
      "iplt                                 module            <module 'iris.plot' from <...>e-packages/iris/plot.py'>\n",
      "iris                                 module            <module 'iris' from '/opt<...>ckages/iris/__init__.py'>\n",
      "jra55arr                             ndarray           63: 63 elems, type `float64`, 504 bytes\n",
      "jra55regannmax_adj_tw                ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "lats                                 DataArray         <xarray.DataArray 'lat' (<...>th\\n    axis:           Y\n",
      "load_annmax                          function          <function load_annmax at 0x3016c23e0>\n",
      "loc                                  float64           18.92703223023463\n",
      "lons                                 DataArray         <xarray.DataArray 'lon' (<...>st\\n    axis:           X\n",
      "loop                                 int               0\n",
      "maindatadir                          str               /Volumes/ExternalDriveD/Thompson_savedarrays/\n",
      "maket23fig2                          int               0\n",
      "maket23fig3                          int               0\n",
      "maket23fig4                          int               0\n",
      "mask_regs                            ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "mask_regs_t                          ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "mask_regs_tw                         ndarray           237: 237 elems, type `float64`, 1896 bytes\n",
      "maskingvs                            str               jra55\n",
      "miroc6_enssz                         int               10\n",
      "modelnames                           list              n=3\n",
      "mpige_enssz                          int               50\n",
      "mpl_cm                               module            <module 'matplotlib.cm' f<...>ckages/matplotlib/cm.py'>\n",
      "myarr                                ndarray           63: 63 elems, type `float64`, 504 bytes\n",
      "myrec                                float64           25.1965\n",
      "nc                                   module            <module 'netCDF4' from '/<...>ges/netCDF4/__init__.py'>\n",
      "np                                   module            <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "numregs                              int               237\n",
      "numregs_ant                          int               21\n",
      "numregs_noant                        int               216\n",
      "numyrs                               int               63\n",
      "obs_max_ret_per                      function          <function obs_max_ret_per at 0x3016c1a80>\n",
      "obs_max_ret_per_removeevent          function          <function obs_max_ret_per<...>moveevent at 0x3016c1940>\n",
      "offset                               list              n=62\n",
      "offset_100                           function          <function offset_100 at 0x3016c2b60>\n",
      "offset_higher                        function          <function offset_higher at 0x107759bc0>\n",
      "offset_higher_removeevent            function          <function offset_higher_r<...>moveevent at 0x3016c18a0>\n",
      "offset_maxval                        function          <function offset_maxval at 0x3016c2840>\n",
      "one_in_hundred                       function          <function one_in_hundred at 0x3016c25c0>\n",
      "one_in_tenthousand                   function          <function one_in_tenthousand at 0x3016c1f80>\n",
      "oneinhundredval                      float64           25.21221971971972\n",
      "orignumlats                          int               4320\n",
      "orignumlons                          int               8640\n",
      "plot_EVT                             function          <function plot_EVT at 0x3016c2340>\n",
      "plot_data_GMST                       function          <function plot_data_GMST at 0x3016c2660>\n",
      "plot_gev                             function          <function plot_gev at 0x3016c1ee0>\n",
      "plot_points                          function          <function plot_points at 0x3016c1bc0>\n",
      "plt                                  module            <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "predicted                            float64           19.308796639022493\n",
      "r                                    int               236\n",
      "random                               module            <module 'random' from '/o<...>ib/python3.11/random.py'>\n",
      "reg                                  int               116\n",
      "reg_mask                             list              n=237\n",
      "reg_mask_t                           list              n=237\n",
      "regannmax                            ndarray           237x63: 14931 elems, type `float64`, 119448 bytes (116.6484375 kb)\n",
      "regcenterlats_noant                  ndarray           216: 216 elems, type `float64`, 1728 bytes\n",
      "regcenterlats_tmp                    list              n=237\n",
      "regcenterlons_noant                  ndarray           216: 216 elems, type `float64`, 1728 bytes\n",
      "regcenterlons_tmp                    list              n=237\n",
      "regcenterpoints                      ndarray           237x2: 474 elems, type `float64`, 3792 bytes\n",
      "region                               int               236\n",
      "region_abs                           ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_abs_t                         ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_abs_tw                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_actual                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_actual_t                      ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_actual_tw                     ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ds                            Dataset           <xarray.Dataset>\\nDimensi<...> Jul  6 13:54:35 2018 ...\n",
      "region_fp                            str               /Volumes/ExternalDriveD/T<...>-1_4-1-0_000000-000000.nc\n",
      "region_mask                          ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_mask_t                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_mask_tw                       ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ord                           ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ord_t                         ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_ord_tw                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper                        ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper_t                      ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper_tw                     ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "region_retper_withtopevents          ndarray           2160x4320: 9331200 elems, type `float64`, 74649600 bytes (71.19140625 Mb)\n",
      "regords_noant                        list              n=237\n",
      "regrid                               function          <function regrid at 0x3016c2480>\n",
      "regs_in_ant                          ndarray           21: 21 elems, type `int64`, 168 bytes\n",
      "remove_max                           function          <function remove_max at 0x3016c2520>\n",
      "remove_max_model                     function          <function remove_max_model at 0x107a20b80>\n",
      "rerunmodelcomp                       int               0\n",
      "return_levels_plot                   function          <function return_levels_plot at 0x3016c1c60>\n",
      "return_period                        function          <function return_period at 0x3048a3f60>\n",
      "scale                                float64           0.7872061373060784\n",
      "scipy                                module            <module 'scipy' from '/op<...>kages/scipy/__init__.py'>\n",
      "shape                                float64           0.3406865582093087\n",
      "sps                                  module            <module 'scipy.stats' fro<...>scipy/stats/__init__.py'>\n",
      "sys                                  module            <module 'sys' (built-in)>\n",
      "ticker                               module            <module 'matplotlib.ticke<...>es/matplotlib/ticker.py'>\n",
      "time_slice                           function          <function time_slice at 0x107a21800>\n",
      "vals_abs_noant                       list              n=237\n",
      "vals_abs_noant_t                     list              n=237\n",
      "vals_abs_noant_tw                    list              n=237\n",
      "vals_actual_noant                    list              n=237\n",
      "vals_actual_noant_t                  list              n=237\n",
      "vals_actual_noant_tw                 list              n=237\n",
      "vals_retper_noant                    list              n=237\n",
      "vals_retper_noant_t                  list              n=237\n",
      "vals_retper_noant_tw                 list              n=237\n",
      "vals_retper_noant_withtopevents      list              n=237\n",
      "vals_retper_noant_withtopevents_tw   list              n=237\n",
      "var                                  str               tw\n",
      "x_val                                ndarray           1000: 1000 elems, type `float64`, 8000 bytes\n",
      "xr                                   module            <module 'xarray' from '/o<...>ages/xarray/__init__.py'>\n",
      "y1                                   int               1961\n",
      "y2                                   int               2023\n",
      "year_max                             function          <function year_max at 0x3016c2ac0>\n",
      "year_max_adjust                      function          <function year_max_adjust at 0x3016c2020>\n",
      "year_max_adjust_1981                 function          <function year_max_adjust_1981 at 0x3016c2980>\n",
      "year_max_multiple_adjust             function          <function year_max_multip<...>le_adjust at 0x3016c2200>\n",
      "year_max_multiple_adjust_1981        function          <function year_max_multip<...>just_1981 at 0x3016c1da0>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b886ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
